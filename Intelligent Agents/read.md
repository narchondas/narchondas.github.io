# Intelligent Agents

This is my learning experience from Module 5 of the MSc Artificial Intelligence

![Capture](https://github.com/user-attachments/assets/82544658-5f24-4a29-9c94-8aaf03abe099)



Use the following links to navigate to the start of the sections


[1. Learning outcomes and action plan PDP](#learning-outcomes)

[2. Collaborative Discussions](#collaborative-discussions)

[3. Seminar and formative activities](#seminar-and-formative-activities)

[4. Development Team Project Report](#development-team-project-report)

[5. Individual Development Project](#individual-development-project)





## Learning outcomes


### In the module Intelligent Agents I shall:

*Understand the motivations for, and appropriate use of, agent-based computing.

*Understand the main agent models in use today and their grounding in artificial intelligence research.

*Acquire the knowledge and skills to develop, deploy and evaluate the tools and techniques of intelligent systems to solve real-world problems.

*Understand contemporary research issues in the area of intelligent agent systems.


### On completion of the module Intelligent Agents, I will be able to:

*Identify and critically analyse agent-based systems, differentiating between architectures and approaches.

*Apply and critically evaluate intelligent agent techniques to real-world problems, particularly where technical risk and uncertainty is involved.

*Deploy critically appropriate software tools and skills for the design and implementation of an agent-based system, bearing in mind applicable legal, social, ethical and professional issues.

*Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real-life perspectives on team roles and organisation.


![ial](https://github.com/user-attachments/assets/2db3f9b4-42c8-4934-b9c7-b1b965c7cb2a)



[Back to the top](#intelligent-agents)



## Professional Skills matrix and action plan PDP


### Self-assessment

* Very motivated to learn about Intelligent Agents and advance with my MSc.

* Focused on timely delivery of good quality assignments.

* Good with time management, note taking and studying new material.

* Lack of a STEM background, so more difficult to get quickly familiar with the concepts and perform the formative acitivities i.e. coding and Protege exercises.


### Set goals

* Learn to identify and critically analyse agent-based systems, differentiating between architectures and approaches

* Apply and critically evaluate intelligent agent techniques to real-world problems, particularly where technical risk and uncertainty is involved.

* Deploy critically appropriate software tools and skills for the design and implementation of an agent-based system, bearing in mind applicable legal, social, ethical and professional issues.

* Systematically develop and implement the skills required to be effective member of a development team in a virtual professional environment, adopting real-life perspectives on team roles and organisation.

* Regularly update my GitHub.


### Develop strategies

* Study the required and additional reading of each Module Unit.

* Take e-notes and highlight the most important sections.

* Understand the formative activities and test my knowledge with examples.

* Prepare all seminar activities.

* Perform the required formative activities of the Module Unit.

* Plan in advance for the assignments.

* Make sure there is sufficient time to fine-tune assignments.

* Gather feedback from tutor and peers.


### Gather resources

* Study all the required and additional resources of each Module Unit. 

* Prepare seminar activities.

* Perform all formative activities.

* Seek other explanatory reliable material on internet (websites, videos, classes etc).

* Reach out to the tutor.


### Create timeline

* Study all required and additional material every week.
  
* Plan in advance the assignments.

* Timely deliver the modelling assignment. 

* Timely submit my e-portfolio.


### Track progress and revise

* Regularly monitor if targets are met.

* Reconsider strategy, if needed.

* Monitor the timely delivery of good quality assignments.



<img width="996" height="542" alt="image" src="https://github.com/user-attachments/assets/67262e02-961d-457a-b520-613c353a7bba" />



[Back to the top](#intelligent-agents)



## Collaborative discussions

### Initial, summary posts & response to peers' posts


### Collaborative Discussion 1



**Agent Based Systems: Discuss what has led to the rise of agent-based systems and the benefits that this approach can offer to organisations.**


**Initial Post**

The rise of agent-based systems is closely tied to the growing complexity of modern computing environments and broader technological trends. Traditional centralised systems are increasingly inadequate for managing dynamic, distributed infrastructures such as supply chains, logistics networks, and smart cities. As highlighted in the lecturecast of Unit 1 (UoEO, n.d.), converging trends like ubiquity, interconnection, intelligence, delegation, and human-orientation have driven the development of systems capable of operating autonomously in uncertain and partially observable environments. The expansion of the Internet of Things (IoT), 5G networks, and edge computing has created conditions where systems must not only act independently but also coordinate and adapt in real time. Wooldridge (2009) defines agents as computational systems embedded in environments that are capable of flexible, autonomous action in pursuit of delegated objectives, with the ability to act proactively, reactively, and socially.

For organisations, agent-based systems offer improvements in scalability, fault tolerance, and decision-making autonomy. In smart manufacturing, agents support decentralised process control and allow for modular, adaptive production systems (Pulikottil et al., 2023). Logistics operations, such as those pioneered by Amazon’s robotics, demonstrate how multi-agent architectures can increase flexibility and reduce human labour costs (Wasesa et al., 2017). In traffic systems, distributed agents enable responsive and efficient traffic flow control across geographically dispersed networks (Wang, 2005). These systems exemplify Wooldridge’s distinction between agents and passive software: agents possess autonomy, control their own actions, and are capable of collaboration and negotiation to meet shared objectives.

 

#### References

Pulikottil, T., Estrada-Jimenez, L.A., Ur Rehman, H. et al. (2023) Agent-based manufacturing — review and expert evaluation. Int J Adv Manuf Technol 127, 2151–2180. https://doi.org/10.1007/s00170-023-11517-8

UoEo, (n.d.) Module Intelligent Agents, Unit 1, Lecturecast.

Wang, F.Y. (2005). Agent-based control for networked traffic management systems in IEEE Intelligent Systems, vol. 20, no. 5, pp. 92-96, Sept.-Oct. 2005, doi: 10.1109/MIS.2005.80

Wasesa, M. Stam, A., van Heck E.  (2017). Investigating agent-based inter-organizational systems and business network performance: Lessons learned from the logistics sector. Journal of Enterprise Information Management 6 March 2017, 30 (2): 226–243. https://doi.org/10.1108/JEIM-07-2015-0069

Wooldridge, M.J. (2009). An Introduction to MultiAgent Systems. John Wiley & Sons



**Summary Post**

The rise of agent-based systems is driven by the growing complexity of modern computing environments and converging technological trends. Centralised systems are increasingly inadequate for managing dynamic, distributed infrastructures such as supply chains, logistics networks, and smart cities. As highlighted in the lecturecast of Unit 1, factors like ubiquity, interconnection, intelligence, delegation, and human-orientation have spurred the development of systems capable of autonomous operation in uncertain and partially observable environments (UoEo, no date). The growth of the Internet of Things (IoT), 5G, and edge computing has created conditions where systems must act independently while coordinating and adapting in real time. Wooldridge (2009) defines agents as computational systems embedded in environments, capable of proactive, reactive, and social behaviour in pursuit of delegated objectives.

For organisations, agent-based systems improve scalability, fault tolerance, and decision-making autonomy. In manufacturing, they enable decentralised process control and adaptive production (Pulikottil et al., 2023). In logistics, multi-agent architectures like Amazon’s robotics enhance flexibility and reduce labour costs (Wasesa, Stam and van Heck, 2017). In traffic management, distributed agents support responsive and efficient flow control (Wang, 2005).

Nonetheless, significant challenges remain. Scalability issues can arise as the number of agents grows, increasing coordination overhead and complexity (Durfee, 2004). When multi-agent systems are spread across many different devices and technologies, it creates more entry points for hackers, making the whole system harder to secure. (Zhang et al., 2025). In healthcare, LLM-based agents face novel risks, including adversarial prompts embedded in online sources that could manipulate medical decisions (Qiu et al., 2025).

Resilience-oriented design can address these issues. In manufacturing, redundant sensors and controllers sustain production if agents fail (Pulikottil et al., 2023). In logistics, authenticated communication and stress testing preserve coordination under pressure (Wasesa, Stam and van Heck, 2017). In traffic systems, anomaly detection and self-healing controls mitigate faulty data and reroute flows automatically (Wang, 2005). Embedding such safeguards is essential to sustaining scalability, reliability, and autonomy (Zhang et al., 2025).

Agent-based systems hold transformative potential for distributed operations, but their long-term success depends on integrating preventive measures and adaptive mechanisms alongside autonomy.

 
#### References

Department for Science and Technology (2025) Shake up of tech and AI usage across NHS and other public services to deliver plan for change. Available at: https://www.gov.uk/government/news/shake-up-of-tech-and-ai-usage-across-nhs-and-other-public-services-to-deliver-plan-for-change (Accessed: 7 August 2025).

Durfee, E.H. (2004) ‘Challenges to scaling up agent coordination’, Distributed Artificial Intelligence Journal.

Pulikottil, T., Estrada-Jimenez, L.A., Ur Rehman, H. et al. (2023) ‘Agent-based manufacturing — review and expert evaluation’, International Journal of Advanced Manufacturing Technology, 127, pp. 2151–2180. doi:10.1007/s00170-023-11517-8.

Qiu, J. et al. (2025) ‘Emerging cyber attack risks of medical AI agents’, arXiv [cs.CR]. Available at: http://arxiv.org/abs/2504.03759.

UoEo (no date) Module Intelligent Agents, Unit 1, Lecturecast.

Wang, F.Y. (2005) ‘Agent-based control for networked traffic management systems’, IEEE Intelligent Systems, 20(5), pp. 92–96. doi:10.1109/MIS.2005.80.

Wasesa, M., Stam, A. and van Heck, E. (2017) ‘Investigating agent-based inter-organizational systems and business network performance: Lessons learned from the logistics sector’, Journal of Enterprise Information Management, 30(2), pp. 226–243. doi:10.1108/JEIM-07-2015-0069.

Wooldridge, M.J. (2009) An introduction to multiagent systems. Chichester: John Wiley & Sons.

Zhang, Y., Li, Y., Zhao, T., Zhu, K., Wang, H. and Vasconcelos, N. (2025) ‘Achilles heel of distributed multi agent systems’, arXiv [Preprint].



#### Response to my peers' posts

The increasing complexity and decentralised nature of modern systems has created a landscape in which traditional centralised computing models often prove inadequate. In response, agent-based systems (ABS) have become an effective paradigm for modelling environments where independent, interactive components must make decisions in parallel. These systems do not operate in isolation but instead function within a dynamic ecosystem of partially observable and often unpredictable variables (Wooldridge, 2009).

Recent developments in computational infrastructure, particularly in IoT, edge computing, and ubiquitous connectivity, have intensified the need for distributed intelligence. In such environments, ABS enable real-time responsiveness through autonomous agents that exhibit goal-oriented, reactive, and socially cooperative behaviours (UoEO, no date). Their strength lies not only in their independence but also in their ability to interact meaningfully with other agents or human operators to align local actions with broader system objectives.

Notably, the capacity of ABS to manage disruptions is increasingly vital. In manufacturing, for instance, the deployment of agents across modular production units supports adaptive operations, enabling continuity during demand shifts or mechanical failures (Pulikottil et al., 2023). Similarly, agent-driven coordination in logistics enhances flexibility in the face of supply chain volatility (Wasesa et al., 2017).

Furthermore, the integration of adjustable autonomy mechanisms allows agents to assess when human intervention is preferable, particularly in high-risk or uncertain conditions (UoEO, no date). This layered decision model not only reinforces system resilience but also reflects an increasing trust in computational agents to act judiciously within delegated boundaries.

Overall, ABS represent a conceptual and technical evolution toward systems that are capable of distributed control, intelligent adaptation, and collaborative behaviour under complexity.

 

#### References

Pulikottil, T., Estrada-Jimenez, L.A., Ur Rehman, H. et al. (2023). Agent-based manufacturing — review and expert evaluation. International Journal of Advanced Manufacturing Technology, 127, 2151–2180. https://doi.org/10.1007/s00170-023-11517-8

UoEO. (n.d.). Module 5: Intelligent Agents – Unit 1 Lecturecast. University of Essex Online.

Wasesa, M., Stam, A., & van Heck, E. (2017). Investigating agent-based inter-organisational systems and business network performance. Journal of Enterprise Information Management, 30(2), 226–243. https://doi.org/10.1108/JEIM-07-2015-0069

Wooldridge, M. J. (2009). An Introduction to MultiAgent Systems (2nd ed.). John Wiley & Sons.



The argument presented offers a timely assessment of the foundational role agents play in modern computing. The definition cited, according to which agents are systems capable of autonomous action in an environment, resonates strongly with core theoretical frameworks (Wooldridge, 2009). This perspective is further supported by the lecturecast of the Unit 1, which characterises agents as entities that perceive, reason, and act under partial control and incomplete information (UoEO, no date).

The observation that agent capabilities are shaped primarily by the constraints of hardware and software is particularly pertinent. As outlined in the UoEO material (no date), agents range from reactive software daemons and control systems to proactive, learning-enabled systems operating in complex environments such as manufacturing or logistics. This flexibility demonstrates the scalability of agent-based systems and their suitability across both physical and digital domains.

The increasing convergence of agent-based models with generative AI, particularly through large language models, introduces a new dimension of capability. With recent developments such as OpenAI’s ChatGPT agents, computational entities are now being deployed to perform knowledge-based tasks previously limited to human professionals (OpenAI, 2025). While this enhances organisational efficiency and reduces the time and cost associated with complex tasks, it also raises important questions around over-reliance and the need for human oversight.

In sum, the post effectively identifies both the technical robustness and emerging challenges associated with agent-based systems. Their increasing autonomy, versatility, and integration into real-world applications underscore their importance in shaping the future of intelligent systems.

 

#### References

OpenAI (2025) Introducing ChatGPT agent: bridging research and action, OpenAI. Available at: https://openai.com/index/introducing-chatgpt-agent/ (Accessed: 3 August 2025).

UoEO (no date) Module 5: Intelligent Agents – Unit 1 Lecturecast. University of Essex Online.

Wooldridge, M. (2009) An Introduction to MultiAgent Systems. 2nd edn. Chichester: John Wiley & Sons.



<img width="955" height="400" alt="image" src="https://github.com/user-attachments/assets/d15c0b7f-9541-487b-a02c-671ac3cce34f" />



### Collaborative Discussion 2



**Agent Communication Languages: What are the potential advantages and disadvantages of the use of agent communication languages such as KQML? How do they compare with method invocation in Python or Java?**


**Initial Post**

The use of agent communication languages (ACLs), such as the Knowledge Query and Manipulation Language (KQML), provides several potential advantages compared with traditional method invocation in Python or Java. First, ACLs are explicitly designed to support communication between autonomous agents, enabling richer forms of interaction inspired by speech act theory, where messages can function as requests, commitments, or declarations rather than simple function calls (Searle, 1969; Finin et al., 1994). This makes ACLs well-suited for open, distributed environments where heterogeneous agents must negotiate, cooperate, or share knowledge without being tightly coupled to a single interface or platform (Wooldridge, 2009).

A second advantage lies in flexibility and autonomy: whereas a method call deterministically executes a specified piece of code, an ACL message allows the receiving agent to decide whether and how to respond, reflecting its goals and local constraints. This distinction highlights the difference between object-oriented invocation and agent-based communication, objects “do it for free,” but agents “do it because they want to” (Wooldridge, 2009).

Nonetheless, ACLs also present notable disadvantages. KQML, for example, suffered from weak standardisation and interoperability problems due to loosely defined semantics and inconsistent implementations (Finin et al., 1994). Additionally, agent communication requires ontology alignment to avoid semantic heterogeneity, a non-trivial challenge when different agents operate with incomplete or private vocabularies (Payne and Tamma, 2014). Finally, ACLs introduce computational overhead compared with lightweight method calls, potentially reducing performance in high-frequency exchanges.

In sum, ACLs prioritise autonomy and expressiveness in distributed systems, but these benefits are balanced by complexity, semantic uncertainty, and efficiency trade-offs.



#### References

Finin, T., Fritzson, R., McKay, D. and McEntire R. (1994) ‘KQML as an agent communication language’, Proceedings of the 3rd International Conference on Information and Knowledge Management (CIKM), ACM, pp. 456–463. Available at: https://dl.acm.org/doi/10.1145/191246.191322

Payne, T.R. and Tamma, V. (2014) ‘Negotiating over ontological correspondences with asymmetric and incomplete knowledge’, Autonomous Agents and Multi-Agent Systems, AAMAS, 13(1), pp. 517-524. Available at:  https://ifmas.csc.liv.ac.uk/Proceedings/aamas2014/aamas/p517.pdf 

Searle, J.R. (1969) Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge University Press. 

Wooldridge, M. (2009) An Introduction to MultiAgent Systems. 2nd edn. Chichester: Wiley.



**Summary Post**

The use of agent communication languages (ACLs), such as the Knowledge Query and Manipulation Language (KQML), offers distinct advantages over traditional method invocation in languages such as Python or Java. ACLs are grounded in speech act theory, which frames communication as more than the execution of functions: messages may serve as requests, commitments, or declarations (Searle, 1969; Finin et al., 1994). This expressiveness makes ACLs particularly well-suited for open, distributed systems, where heterogeneous agents must cooperate, negotiate, or exchange knowledge without relying on tightly coupled interfaces (Wooldridge, 2009).

A key advantage of ACLs lies in the autonomy they confer. Whereas method calls deterministically execute specified code, ACL messages empower agents to decide whether and how to respond in accordance with their goals and constraints. As Wooldridge (2009) notes, objects “do it for free,” but agents “do it because they want to.” This autonomy, as further emphasised by Jennings, Sycara and Wooldridge (1998), underpins negotiation-based problem solving in distributed environments, thereby enabling more adaptive forms of interaction than object-oriented invocation alone.

Nevertheless, ACLs also bring challenges. KQML in particular suffered from weak standardisation, leading to interoperability issues due to loosely defined semantics and inconsistent implementations (Finin et al., 1994). Furthermore, effective communication requires ontology alignment to ensure semantic interoperability, yet mismatches in shared vocabularies can undermine otherwise coherent dialogues (Payne and Tamma, 2014). These issues illustrate the trade-offs between expressiveness and efficiency: ACLs enable richer forms of interaction, but at the cost of added complexity, semantic uncertainty, and computational overhead.

In sum, ACLs highlight the difference between object invocation and agent communication, privileging autonomy, negotiation, and semantic richness, but their benefits must be balanced against practical difficulties of implementation and interoperability.



#### References

Finin, T., Fritzson, R., McKay, D. and McEntire, R. (1994) ‘KQML as an agent communication language’, Proceedings of the 3rd International Conference on Information and Knowledge Management (CIKM), ACM, pp. 456–463. Available at: https://dl.acm.org/doi/10.1145/191246.191322

Jennings, N.R., Sycara, K. and Wooldridge, M. (1998) ‘A roadmap of agent research and development’, Autonomous Agents and Multi-Agent Systems, 1(1), pp. 7–38.

Payne, T.R. and Tamma, V. (2014) ‘Negotiating over ontological correspondences with asymmetric and incomplete knowledge’, Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), pp. 517–524. Available at: https://ifmas.csc.liv.ac.uk/Proceedings/aamas2014/aamas/p517.pdf

Searle, J.R. (1969) Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge University Press.

Wooldridge, M. (2009) An Introduction to MultiAgent Systems. 2nd edn. Chichester: Wiley.



#### Response to my peers' posts



Your post makes an important point about the abstraction and interoperability ACLs such as KQML provide. Building on this, one of their key contributions lies in the grounding of performatives in speech act theory, linking messages to agents’ cognitive states such as belief, knowledge, desire, and intention (Labrou and Finin, 1994; Labrou and Finin, 1997). This means that an ACL message is not merely a data transfer but an expression of intent, enabling richer communicative acts like commitments, negotiations, or declarations.

A second advantage is the structuring of multi-step interactions through 'conversation policies'. These policies formally specify how performatives like ask-if, tell, or sorry can be sequenced, ensuring coherent dialogues across heterogeneous agents (Labrou and Finin, 1997). Such mechanisms extend far beyond conventional method calls, which lack protocol-level semantics and assume deterministic execution.

However, the drawbacks are equally significant. KQML long suffered from a lack of formally defined semantics, resulting in inconsistent implementations and undermining standardisation efforts (Finin et al., 1994). Moreover, agent conversations impose computational overhead compared with lightweight method invocations, and their success ultimately depends on shared ontologies to ensure semantic alignment across domains (Payne and Tamma, 2014). These requirements make ACLs more expressive but also more complex than direct method calls in Python or Java.

In short, ACLs prioritise autonomy and semantic richness, supporting negotiation and cooperation in distributed environments, but this expressiveness is balanced by efficiency costs and unresolved challenges of interoperability.


#### References

Finin, T., Fritzson, R., McKay, D. and McEntire, R. (1994) ‘KQML as an agent communication language’, Proceedings of the 3rd International Conference on Information and Knowledge Management (CIKM). ACM, pp. 456–463. Available at: https://dl.acm.org/doi/10.1145/191246.191322

Labrou, Y. and Finin, T. (1994) ‘A semantics approach for KQML—a general purpose communication language for software agents’, Proceedings of the 3rd International Conference on Information and Knowledge Management (CIKM). ACM, pp. 447–455. Available at: https://www.researchgate.net/publication/221614440_A_Semantics_Approach_for_KQML

Labrou, Y. and Finin, T. (1997) ‘Semantics and conversations for an agent communication language’, Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI), pp. 584–591.

Payne, T.R. and Tamma, V. (2014) ‘Negotiating over ontological correspondences with asymmetric and incomplete knowledge’, Autonomous Agents and Multi-Agent Systems, 13(1), pp. 517–524. Available at: https://ifmas.csc.liv.ac.uk/Proceedings/aamas2014/aamas/p517.pdf

Wooldridge, M. (2009) An Introduction to MultiAgent Systems. 2nd edn. Chichester: Wiley.



Your post rightly highlights abstraction and interoperability as central strengths of ACLs such as KQML. I would emphasise, however, one additional but often overlooked advantage: ACLs formalise not only individual messages but also the structure of conversations. Labrou and Finin (1997) demonstrate that KQML provides explicit conversation policies, which define permissible sequences of performatives (e.g., ask-if followed by tell or sorry). This ability to embed protocol-level semantics enables multi-agent systems to sustain coherent dialogues, something method invocation in Python or Java cannot provide, as it remains limited to isolated, deterministic calls.

On the downside, a major limitation of ACLs is precisely the lack of stable semantic standardisation. Early versions of KQML were criticised for relying on loosely defined semantics, which often led to inconsistent implementations and hindered true interoperability across platforms (Finin et al., 1994). Even with later semantic frameworks, effective communication still presupposes agreed ontologies, making ACLs far more fragile in practice than the lightweight reliability of direct method calls.

In this sense, ACLs excel in modelling dialogues between autonomous agents, but their promise of universal interoperability remains constrained by unresolved semantic challenges.


#### References

Finin, T., Fritzson, R., McKay, D. and McEntire, R. (1994) ‘KQML as an agent communication language’, Proceedings of the 3rd International Conference on Information and Knowledge Management (CIKM). ACM, pp. 456–463.

Labrou, Y. and Finin, T. (1997) ‘Semantics and conversations for an agent communication language’, Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI), pp. 584–591.



<img width="866" height="464" alt="image" src="https://github.com/user-attachments/assets/6202e02a-6cb9-4777-b0cb-c2cc974fd3d3" />



### Collaborative Discussion 3


**The advent of new technologies supported by Deep Learning models mean that it is now possible to generate ‘new’ content, for example, Dall-E AI to generate images or ChatGPT to create prose. Do you think that these new technologies offer any ethical issues that should be considered, and if not, why not?**


**Initial Post**


The rapid rise of generative AI technologies, such as DALL-E for images and ChatGPT for prose, has intensified debates on copyright and creativity. These systems rely on deep learning models trained on vast corpora, often including copyrighted works. While some jurisdictions allow text-and-data mining under fair use or statutory exceptions, scholars emphasise that transparency about datasets and fair remuneration mechanisms are essential to avoid the uncompensated extraction of creative labour (Tyagi, 2024; Senftleben, 2023).

Copyright law has long been grounded in the requirement of human intellectual creativity, yet works produced without substantial human involvement disrupt this foundation and may undermine proper recognition of human authors (Ginsburg and Budiardjo, 2019). Moreover, research shows that although AI can enhance individual productivity, it tends to reduce the diversity of outputs, privileging statistically common patterns and potentially narrowing cultural expression (Doshi et al., 2024). This creates ethical concerns about homogenisation and the underrepresentation of minority voices.

Addressing these issues does not mean rejecting generative AI, but embedding its development within responsible frameworks. Three elements are crucial. First, enforceable opt-outs allow creators to signal that their works should not be used in training datasets, ensuring respect for their choices. Second, licensing or collective management schemes enable works to be lawfully included in AI training, while securing fair remuneration for rightsholders. Finally, clear attribution rules guarantee that human contributors receive appropriate credit and that audiences can distinguish between human-created and AI-assisted content.

In this way, society can balance the legitimate public interest in advancing knowledge with the ethical duty to safeguard authors’ rights and preserve cultural diversity. Generative AI should therefore be understood as an assistive tool that augments, rather than substitutes, human intelligence and creative agency.


#### References
Doshi, A.R., Tang, A., Leung, M., Lin, A., Melkonyan, A., Liu, A., Dorn, C., Sethi, A., Prasad, P., Xu, C., Bailey, J. and Yang, D. (2024) ‘Generative AI enhances individual creativity but reduces diversity’, Science Advances, 10(21), eadn5290. https://doi.org/10.1126/sciadv.adn5290

Ginsburg, J.C. and Budiardjo, L.A. (2019) ‘Authors and Machines’, Berkeley Technology Law Journal, 34(2), pp. 343–430. Available at https://btlj.org/data/articles2019/34_2/01_Ginsburg_Web.pdf [Accessed on 9 September 2025]

Senftleben, M. (2023) ‘Generative AI and Author Remuneration’, IIC – International Review of Intellectual Property and Competition Law, 54(12), pp. 1535–1560. Available at https://link.springer.com/article/10.1007/s40319-023-01399-4 [Accessed on 9 September 2025]

Tyagi, K. (2024) ‘Copyright, text & data mining and the innovation dimension of generative AI’, Journal of Intellectual Property Law & Practice, 19(7), pp. 557–566. https://doi.org/10.1093/jiplp/jpae047



**Summary Post**


The emergence of generative AI technologies such as DALL-E and ChatGPT has transformed debates on authorship, creativity, and cultural production. These systems, trained on extensive datasets often containing copyrighted material, raise significant ethical and legal challenges concerning ownership, fair use, and the recognition of creative labour. Scholars argue that while certain jurisdictions allow text-and-data mining under fair use or statutory exceptions, transparency about training datasets and equitable remuneration mechanisms remain crucial to prevent the uncompensated extraction of artistic value (Tyagi, 2024; Senftleben, 2023; Al-Kfairy et al., 2024).

Copyright frameworks built upon the notion of human intellectual creation are now strained by works produced without substantial human input (Ginsburg and Budiardjo, 2019). The consequences extend beyond legal questions to the cultural and aesthetic sphere. Generative AI, although capable of enhancing productivity, often privileges statistically common patterns, which can homogenise outputs and limit the diversity of creative expression (Doshi et al., 2024). As Hagendorff (2024) notes, such tendencies risk marginalising experimental and minority artistic voices, thereby diminishing cultural pluralism.

To mitigate these concerns, responsible governance should combine enforceable opt-outs for creators, collective licensing schemes to ensure fair compensation, and transparent attribution rules that distinguish human from AI-generated content. Yet the persistence of asymmetries between major technology corporations and individual artists underscores the need for more equitable power relations within creative ecosystems.

Ultimately, generative AI should be viewed not as a replacement for human ingenuity but as an augmentative tool that supports and extends it. Embedding ethical safeguards, dataset transparency, and cultural diversity within AI development is essential to ensure that innovation proceeds in harmony with the protection of authors’ rights and the enrichment of creative expression.


#### References

Al-Kfairy, M. et al. (2024) ‘Ethical challenges and solutions of generative AI: An interdisciplinary perspective’, Informatics, 11(3), p. 58.

Doshi, A.R. et al. (2024) ‘Generative AI enhances individual creativity but reduces diversity’, Science Advances, 10(21), eadn5290.

Ginsburg, J.C. and Budiardjo, L.A. (2019) ‘Authors and Machines’, Berkeley Technology Law Journal, 34(2), pp. 343–430.
Hagendorff, T. (2024) ‘Mapping the ethics of generative AI: A comprehensive scoping review’, Minds and Machines, 34(4), p. 39.

Senftleben, M. (2023) ‘Generative AI and Author Remuneration’, IIC – International Review of Intellectual Property and Competition Law, 54(12), pp. 1535–1560.

Tyagi, K. (2024) ‘Copyright, text & data mining and the innovation dimension of generative AI’, Journal of Intellectual Property Law & Practice, 19(7), pp. 557–566.



#### Response to my peers' posts


You raise key ethical concerns about authorship and creativity in generative AI. While these systems undeniably challenge traditional notions of originality, they can also enhance creativity by expanding human expressive capacities. As Boden (2016) explains, creativity often arises through the combinational reconfiguration of existing ideas. In this sense, AI models trained on vast internet datasets may facilitate new artistic pathways, generating hybrid forms of art that humans alone might not have conceived.

However, such recombination relies on pre-existing works, raising unresolved questions about ownership and recognition. When AI systems emulate identifiable artistic styles, the boundary between inspiration and imitation becomes blurred (Abbott and Rothman, 2023). Moreover, as Gervais (2023) argues, authorship in the AI era should be reconsidered as collaborative, ensuring that human creators receive due acknowledgment and remuneration. Without transparent attribution, ethical use of training data, and fair compensation mechanisms, these tools risk appropriating rather than augmenting creative labour.

Thus, while AI can democratise creativity and stimulate novel aesthetic directions, it simultaneously intensifies the urgency to protect artistic rights. A balanced governance framework, combining licensing schemes, dataset transparency, and attribution standards, is essential to ensure that generative AI becomes a partner in human creativity rather than its silent substitute.


#### References

Abbott, R. and Rothman, E. (2023) ‘Disrupting creativity: Copyright law in the age of generative artificial intelligence’, Florida Law Review, 75, p. 1141.

Boden, M.A. (2016) AI: Its nature and future. Oxford: Oxford University Press.

Gervais, D.J. (2023) ‘The machine as author’, Harvard Journal of Law & Technology, 36(2), pp. 311–364. Available at: https://jolt.law.harvard.edu/

Senftleben, M. (2023) ‘Generative AI and Author Remuneration’, IIC – International Review of Intellectual Property and Competition Law, 54(12), pp. 1535–1560. https://doi.org/10.1007/s40319-023-01399-4



Your post rightly highlights the transformative yet ethically complex nature of generative AI. I particularly agree that the question of originality and ownership lies at the heart of the debate. While systems such as ChatGPT and DALL-E democratise content creation and expand access to creative tools, their reliance on large-scale datasets of human-made works raises unresolved issues of authorship and attribution. As Ginsburg and Budiardjo (2019) observe, copyright law is premised on human intellectual creation. Outputs generated autonomously by AI therefore challenge the legal and moral framework that protects creative labour.

Nonetheless, it could be argued that generative AI does not merely imitate but enables augmented creativity. Boden (2016) defines such creativity as 'combinational', where novelty arises through the reconfiguration of existing ideas, a process AI models emulate statistically. When guided by human intent, these tools can foster new aesthetic expressions and interdisciplinary collaboration, amplifying rather than diminishing human ingenuity (Franceschelli and Musolesi, 2024).

The challenge, then, is not the existence of AI-generated art itself but ensuring ethical governance that preserves transparency, fair remuneration, and clear attribution. As Senftleben (2023) emphasises, establishing collective licensing and opt-out mechanisms is essential to reconcile innovation with respect for creators’ rights.


#### References

Boden, M.A. (2016) AI: Its Nature and Future. Oxford: Oxford University Press.

Franceschelli, G. and Musolesi, M. (2024) ‘Generative AI and the philosophy of creativity: Novelty, value and meaning’, AI & Society, 39(3), pp. 1123–1139. Available at https://www.mircomusolesi.org/papers/aiandsociety24.pdf  [Accessed on 8 October 2025]

Ginsburg, J.C. and Budiardjo, L.A. (2019) ‘Authors and Machines’, Berkeley Technology Law Journal, 34(2), pp. 343–430. Available at: https://btlj.org/data/articles2019/34_2/01_Ginsburg_Web.pdf 

Senftleben, M. (2023) ‘Generative AI and Author Remuneration’, IIC – International Review of Intellectual Property and Competition Law, 54(12), pp. 1535–1560. https://doi.org/10.1007/s40319-023-01399-4






<img width="890" height="524" alt="image" src="https://github.com/user-attachments/assets/65ee5769-dceb-404d-8d7a-2be46c87ea1c" />





[Back to the top](#intelligent-agents)



## Seminar and formative activities 



### Unit Formative Activities



**Unit 6**

**Create an agent dialogue, using KQML and KIF, between two agents (named Alice and Bob).  Alice is an agent designed to procure stock and Bob is an agent that controls the stock levels for a warehouse.  This dialogue should see Alice asking Bob about the available stock of 50 inch televisions, and also querying the number of HDMI slots the televisions have.**

Alice is a procurement agent and Bob is a warehouse inventory agent.  The dialogue covers: (1) availability of 50-inch televisions, and (2) their HDMI port count.

**Message 1**

**Alice asks Bob: How many 50-inch televisions are in stock?**

(kqml

  (performative ask-one)
  
  (:sender Alice)
  
  (:receiver Bob)
  
  (:language KIF)
  
  (:content
  
    (stock-level (Television 50-inch) ?n)))
    

**Message 2**

**Bob replies: There are 84 units.**

(kqml

  (performative tell)
  
  (:sender Bob)
  
  (:receiver Alice)
  
  (:language KIF)
  
  (:in-reply-to Message-1)
  
  (:content
  
    (= (stock-level (Television 50-inch)) 84)))
    

**Message 3**

**Alice asks Bob: How many HDMI slots do these televisions have?**

(kqml

  (performative ask-one)
  
  (:sender Alice)
  
  (:receiver Bob)
  
  (:language KIF)
  
  (:content
  
    (hdmi-slots (Television 50-inch) ?m)))

**Message 4**

**Bob replies: They have 3 HDMI slots.**

(kqml

  (performative tell)
  
  (:sender Bob)
  
  (:receiver Alice)
  
  (:language KIF)
  
  (:in-reply-to Message-3)
  
  (:content
  
    (= (hdmi-slots (Television 50-inch)) 3)))



   **Unit 8** 

   **Create a constituency-based parse tree for the following phrases:**

   **The government raised interest rates.**
   
   (S
   
  (NP-SBJ (DT The) (NN government))
  
  (VP (VBD raised)
  
      (NP (NN interest) (NNS rates)))
      
  (. .))
  

S

├── NP-SBJ

│   ├── DT  The

│   └── NN  government

├── VP

│   ├── VBD raised

│   └── 

│       ├── NN  interest

│       └── NNS rates

└── .   .


**The internet gives everyone a voice.**

(S

  (NP-SBJ (DT The) (NN internet))
  
  (VP (VBZ gives)
  
      (NP (NN everyone))
      
      (NP (DT a) (NN voice)))
      
  (. .))
  

S

├── NP-SBJ

│   ├── DT  The

│   └── NN  internet

├── VP

│   ├── VBZ gives

│   ├── NP

│   │   └── NN  everyone

│   └── NP

│       ├── DT  a

│       └── NN  voice

└── .   .

**The man saw the dog with the telescope.**

(S

  (NP-SBJ (DT The) (NN man))
  
  (VP (VBD saw)
  
      (NP (DT the) (NN dog))
      
      (PP (IN with)
      
          (NP (DT the) (NN telescope))))
          
  (. .))
  

S

├── NP-SBJ

│   ├── DT  The

│   └── NN  man

├── VP

│   ├── VBD saw

│   ├── NP

│   │   ├── DT  the

│   │   └── NN  dog

│   └── PP

│       ├── IN  with

│       └── NP

│           ├── DT  the

│           └── NN  telescope

└── .   .



**Unit 10**

**You are required to research an application of Deep Learning that you think is going to have an impact on society (whether that is positive or negative).**


**Facial Recognition & Surveillance**

**Overview of the technology**

Facial recognition technology (FRT) is a biometric system designed to identify or verify individuals by analysing their facial features. It is widely used in domains such as law enforcement, border security, access control, and increasingly in public surveillance systems (Garvie, Bedoya and Frankle, 2016). In practice, it allows authorities and organisations to track, recognise, and monitor individuals across different spaces, often without their explicit consent, raising significant ethical and legal concerns (Smith and Miller, 2021).

**How it works**

Modern FRT operates through a multi-stage pipeline. First, faces are detected within images or video streams using object detection algorithms. The identified faces are then aligned and normalised to a consistent orientation. Deep learning models, particularly convolutional neural networks (CNNs), extract discriminative features, transforming the face into a numerical embedding that captures identity-related patterns (Schroff, Kalenichenko and Philbin, 2015). These embeddings are compared against databases using similarity metrics to either verify or identify a subject. While the accuracy of such systems has significantly improved with deep learning, performance can still degrade under conditions of occlusion (masks, glasses), poor lighting, or demographic imbalance in training data (Buolamwini and Gebru, 2018).

**Potential impacts**

The societal impacts of FRT are profound and multidimensional. On the positive side, it can enhance security, aid in locating missing persons, and support faster identification in emergencies (Introna and Wood, 2004). However, there are substantial risks. Misidentifications can lead to wrongful arrests and discrimination, particularly against marginalised groups, as studies show higher error rates for women and people of colour (Buolamwini and Gebru, 2018). The pervasive collection of biometric data also threatens privacy and civil liberties, creating “chilling effects” on public life (people modify behaviour knowing they are watched) and freedom of expression (Smith and Miller, 2021). Furthermore, FRT can enable mass surveillance and mission creep (using technology beyond its original purpose) when deployed without clear regulatory safeguards (Garvie, Bedoya and Frankle, 2016). Although regulatory and technical proposals such as transparency requirements and fairness-oriented model training are emerging, the ethical challenges of balancing security with fundamental rights remain unresolved (Introna and Wood, 2004).


#### References

Buolamwini, J. and Gebru, T. (2018) ‘Gender shades: Intersectional accuracy disparities in commercial gender classification’, Proceedings of Machine Learning Research, 81, pp. 1–15.

Garvie, C., Bedoya, A. and Frankle, J. (2016) The perpetual line-up: Unregulated police face recognition in America. Georgetown Law Center on Privacy & Technology.

Introna, L. and Wood, D. (2004) ‘Picturing algorithmic surveillance: The politics of facial recognition systems’, Surveillance & Society, 2(2/3), pp. 177–198.

Schroff, F., Kalenichenko, D. and Philbin, J. (2015) ‘FaceNet: A unified embedding for face recognition and clustering’, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 815–823.

Smith, R. and Miller, K. (2021) ‘Ethical implications of facial recognition in law enforcement’, AI & Society, 36(3).



  <img width="1024" height="768" alt="image" src="https://github.com/user-attachments/assets/1730cc7b-320c-48ba-ad5c-826557b62df2" />




[Back to the top](#intelligent-agents)



## Development Team Project Report

[**Group D Contract**](https://docs.google.com/document/d/1RhPnR619GzCJswkbZsA7rtuLk7V3z4n_D2sXLvpiNvM/edit?tab=t.0)


**This assignment sees you positioned as a team of software consultants and specialists in agent design and development. You are required to develop an agent that is capable of performing tasks for an organisation with domain-specific requirements.**

**Authors: Elias Medig, Mohamed Khaled Eissa Almail Alzaabi & Nikolaos Archontas**

**Introduction**

This report presents the design and architecture of a multi-agent system to automate and support business processes in the Digital Forensics domain of a fictional company. Its purpose is to define business requirements, architecture, methodology, and key challenges. Agent-based systems are well suited to this field as they combine autonomy, reactivity, and social ability (Wooldridge, 2009). Their application in corporate cybersecurity reflects the shift towards delegating repetitive monitoring tasks to intelligent systems (Russell and Norvig, 2021).

The company operates in a mixed IT environment with Windows and Linux endpoints. To support scalability and collaboration, it uses Microsoft Azure for storage and compute, integrated with the Microsoft ecosystem, including Power BI, Teams, and productivity tools.


**Business Requirements**

The agent must support secure file handling, metadata extraction and analysis, content inspection, and structured reporting to assist investigators. Users include law enforcement, corporate security, and compliance officers who need tools capable of scanning large file volumes, detecting forensic artefacts, and preserving evidential integrity with full auditability. In short, the agent should collect, process, and present digital forensic evidence such as log files, metadata, and network traces.

The agent should deliver:

●	File identification and collection: Extract relevant files (Office documents, PDFs, executables).

●	Metadata analysis and integrity checking: Capture timestamps, authorship, and apply cryptographic hashing.

●	Malware detection: Scan for virus signatures, malware, or encrypted payloads.

●	PII detection: Identify names, emails, phone numbers, or financial data for GDPR compliance.

●	Anonymisation and redaction: Mask PII before storage in shared repositories.

●	Classification and tagging: Categorise files by sensitivity or risk.

●	Audit logging: Record all actions for full traceability.

●	Reporting and visualisation: Generate structured reports and dashboards.

●	Secure storage: Store outputs in encrypted repositories with access control.

These requirements reflect principles of reactivity and accountability in multi-agent systems (Brooks, 1991; Wooldridge, 2009).


**Functional Requirements**

The agent must identify, and extract specified file types, analyse metadata, verify integrity, detect malware, and locate and anonymise PII. Files should be classified by sensitivity, with all actions logged to ensure accountability. Processed outputs must be securely stored and presented with structured datasets and visual summaries for rapid interpretation. Automation ensures consistency and reliability, core attributes of agent-based systems (Wooldridge, 2009).


**Non-Functional Requirements**

The system should scale to large file volumes without loss of performance and remain accurate in detection. Security is critical: data must be encrypted, with access tightly controlled. Audit logs must be comprehensive, the system extensible for new formats or rules, and maintainable through modular updates. Compliance with GDPR and data protection policies is essential. These qualities align with layered architectures such as InteRRaP, which emphasise modularity and adaptability in dynamic environments (Russell and Norvig, 2021).


**Expected Business Benefits**

Automating file scanning and analysis reduces manual effort and improves speed. By detecting malware and ensuring data integrity, the agent strengthens cybersecurity and minimises breach risks. Automated PII handling enhances compliance, while classification and reporting increase transparency. Overall, the system delivers efficiency gains, cost savings, improved risk management, and greater organisational trust. Such benefits demonstrate the value of delegating operational monitoring tasks to intelligent agents (Russell and Norvig, 2021).


<img width="504" height="651" alt="image" src="https://github.com/user-attachments/assets/8543c5cd-7c01-48b1-9b33-8ce946703415" />


**System Architecture**

The proposed system uses a hybrid layered architecture modelled on InteRRaP, combining reactive, planning, and cooperative layers to balance responsiveness with reasoning (Wooldridge, 2009).

●	Reactive layer: Provides immediate safeguards, such as malware detection or blocking suspicious access.

●	Planning layer: Manages workflows including file collection, metadata analysis, verification, and classification.

●	Cooperative layer: Enforces compliance rules, generates reports and dashboards, and ensures integration with external services.

Control flows upward when lower layers cannot manage an event (bottom-up activation) and downward when higher layers issue executable plans (top-down execution) (see Annex, Activity Diagram, and High-Level Design). This two-pass flow, central to InteRRaP, ensures responsiveness and structured reasoning (Brooks, 1991; Maes, 1991).


<img width="750" height="294" alt="image" src="https://github.com/user-attachments/assets/9855c4da-b5a4-484d-aa1a-13bb07124a58" />

Figure 1: Activity Diagram

<img width="729" height="296" alt="image" src="https://github.com/user-attachments/assets/1ab89f7a-12db-4459-9aea-9b68628b6928" />
 
Figure 2: High Level Design

<img width="753" height="449" alt="image" src="https://github.com/user-attachments/assets/da3daa3a-6cc7-488e-af5d-d295c2021604" />
 
Figure 3: Sequence Diagram 


**Technology and Communication**

Implementation will use Python, chosen for its strong ecosystem in security and data handling. Core libraries include hashlib for hashing, pytsk3/dfVFS for forensic file access, pandas for data processing, matplotlib for visualisation, SQLite for lightweight encrypted storage.  This stack ensures scalability, auditability, and compliance while reducing development risk (Wooldridge, 2009).

For communication, the design adopts KQML/Knowledge Query and Manipulation Language, which uses performatives such as inform, request, and query to express message intent (Finin et al., 1994; Searle, 1969). Although KQML lacks strict semantics and transport definitions, limiting interoperability, its performatives remain useful for clear agent interactions when paired with modern protocols.


**Development Methodology**

The project will follow an iterative, incremental approach inspired by agile principles. Development will begin with core functions such as file retrieval and hashing, before extending to malware detection, PII handling, and reporting. Each iteration delivers testable components validated against requirements and refined by feedback. This approach reduces complexity risks and fits the modular, layered architecture (Wooldridge, 2009).

**Challenges & Justification**

Technical challenges include managing large file volumes, addressed through efficient parsing and sampling. Ethical issues concern user privacy, requiring GDPR-compliant detection, anonymisation, and secure storage of PII. Legal challenges involve maintaining chain of custody for admissible evidence, addressed through audit logging and immutable action records. These reflect best practices in agent-based design, where modularity, accountability, and compliance are vital (Wooldridge, 2009).

Scholarly reviews highlight that AI-enabled digital forensics remains uneven, partly due to the absence of standardised datasets and reproducible benchmarks, which hinders comparability across tools (Ragho and Chaudhari, 2025). Although deep learning offers accuracy gains, its opacity and adversarial fragility undermine forensic reliability (Fattahi, 2024). These issues underscore the need for explainable AI, adversarial testing, and shared evaluation standards.

Critically, InteRRaP offers significant strengths by combining reactive safeguards with planning and cooperative reasoning, making it well suited to forensic tasks in dynamic environments (Wooldridge, 2009). Yet layered architectures can increase design complexity and lack the formal semantics of purely logic-based approaches (Russell and Norvig, 2021). Despite these trade-offs, InteRRaP remains a pragmatic choice for balancing responsiveness, planning, and accountability.


**Conclusion**

This project proposed the design of an autonomous agent to support digital forensics in a corporate cybersecurity setting. Business, functional, and non-functional requirements were defined, centred on secure file handling, metadata analysis, malware detection, PII anonymisation, and reporting. These were translated into a hybrid layered architecture inspired by InteRRaP, combining reactive safeguards, workflow planning, and cooperative compliance enforcement.

The Python-based technology stack with specialist forensic libraries makes the design both robust and feasible. KQML provides clarity in agent communication design, complemented by modern protocols for interoperability.

The system offers clear benefits: reduced manual effort, improved consistency, enhanced GDPR compliance, and strengthened organisational trust. Key challenges remain in data scalability, privacy protection, and evidential integrity, but these are mitigated through efficient data processing, encryption, and comprehensive audit logging. Literature further highlights the need for explainable and reproducible AI practices (Ragho and Chaudhari, 2025; Fattahi, 2024).

Overall, the agent demonstrates how intelligent systems can automate complex forensic tasks, offering a scalable and pragmatic solution that supports efficiency, compliance, and accountability (Russell and Norvig, 2021).


[Appendix](https://docs.google.com/document/d/1TOFQ_LlSlDj97TQNznrwBXjlEIozvM_YGEJDQn0K1PY/edit?tab=t.0)


#### References

Brooks, R. A. (1991). “Intelligence Without Representation.” Artificial Intelligence, 47(1–3), 139–159.

Fattahi, J. (2024). Machine Learning and Deep Learning Techniques Used in Cybersecurity and Digital Forensics: a Review. arXiv:2501.03250 [cs.CR], submitted 24 December 2024. Available at: arXiv.org [Accessed on2 September 2025].

Finin, T., Fritzson, R., McKay, D., & McEntire, R. (1994). “KQML as an agent communication language.” CIKM.

Searle, J. R. (1969). Speech Acts. CUP. 

Maes, P. (1991). “The Agent Network Architecture (ANA).” SIGART Bulletin, 2(4), 115–120. 

Ragho, S. R. & Chaudhari, N. (2025). Artificial Intelligence in Digital Forensics: A Review of Cyber-Attack Detection Models and Frameworks. Journal of Information Systems Engineering and Management, 10(57s), published 19 July 2025. Available at: JISEM-Journal.com [Accessed on 2 September 2025].

Wooldridge, M. J. (2009). An Introduction to Multiagent Systems. Wiley.




<img width="1536" height="864" alt="image" src="https://github.com/user-attachments/assets/578a5914-ca8d-4a31-81eb-a090a9a927f0" />



[Back to the top](#intelligent-agents)




## Individual Development Project



### Individual Development Project: Presentation

[Module 5 Individual Development Presentation](https://docs.google.com/presentation/d/12aYwoeKXVCTZB6u6iCNMxIu2LfREVIQbgf4FkqQzNLY/edit?slide=id.p1#slide=id.p1)



### Transcript of the presentation's audio file

[Module 5 Transcript of the presentation's audio file](https://docs.google.com/document/d/1YOLNobXpc8Pj2nwEATruk4_VLM_iksWM0ZaKXCFEn4A/edit?tab=t.0)



### README file

[Module 5 README file](https://docs.google.com/document/d/1XxX12eyFgJuOIQbT4BuL3kVGaqqaR3_gTb1_FRA4G0s/edit?tab=t.0)



### Colab Notebook video

[Module 5 Colab Notebook video](https://drive.google.com/file/d/1j2X3XqKBJjxPmA-zVT_PvZjEGKvd9C-t/view?usp=drive_link)




<img width="1144" height="501" alt="image" src="https://github.com/user-attachments/assets/222cf1de-510e-4597-adc1-6c43a2197939" />



[Back to the top](#intelligent-agents)


[Go to main Menu](https://narchondas.github.io/)


